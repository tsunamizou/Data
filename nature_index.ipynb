{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nature_index.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO5slumLHeb5CZj25Et57Xa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsunamizou/Hindawi/blob/main/nature_index.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "EeIJxOXxzzuI"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This scraper is to get all the affiliated institutions of the leading 500 institutions from China"
      ],
      "metadata": {
        "id": "jdksMMIqz4Yz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "link = \"https://www.natureindex.com/supplements/nature-index-2022-big-5/tables/overall\"\n",
        "page = requests.get(link)\n",
        "soup = BeautifulSoup (page.content, \"html.parser\")\n"
      ],
      "metadata": {
        "id": "6ltnmcU50Nes"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tbody = soup.find('tbody')\n",
        "rows = tbody.find_all('tr')\n",
        "\n"
      ],
      "metadata": {
        "id": "Bo1r5kV3JTQH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "url_list = []\n",
        "cn_list = []\n",
        "for row in rows:\n",
        "  if row.find(class_=\"country\").text == 'China':  \n",
        "    url_link = row.find('a')\n",
        "    full_link = 'https://www.natureindex.com' + url_link['href']\n",
        "    cn_name = row.find('a').text.replace('\\n','').strip()\n",
        "    url_list.append(full_link)\n",
        "    cn_list.append(cn_name)\n",
        "\n",
        "print(url_list)\n",
        "print(cn_list)\n",
        "len(cn_list)"
      ],
      "metadata": {
        "id": "Hfymx6r6QDcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cn_affli_list = []\n",
        "\n",
        "# There could be two divs under the \"Relationships\" section, the first one starts with the institute name followed by a list of directly affilliated institutes, which is what we want.\n",
        "# The other one starts with 'Affiliated joint institutions and consortia', which is not what we want\n",
        "\n",
        "for test_link in url_list:\n",
        "  detail = requests.get(test_link)\n",
        "  soup_2 = BeautifulSoup(detail.content, \"html.parser\")\n",
        "\n",
        "  try:\n",
        "    ins_name = soup_2.find('h3',class_=\"u-sans-serif u-mb-8\").text\n",
        "  except AttributeError:\n",
        "    ins_name = 'N/A'\n",
        "  if ins_name == 'Affiliated joint institutions and consortia':\n",
        "    ins_name = 'N/A'\n",
        "  if ins_name == 'N/A':\n",
        "    affli_list = 'N/A'\n",
        "  else:\n",
        "    affli_table = soup_2.find('ul', class_=\"font-weight-bold\")\n",
        "    try:\n",
        "      affli_list = [ affli.find('a').text for affli in affli_table.find_all('li')]\n",
        "    except AttributeError:\n",
        "      affli_list='N/A'\n",
        "  cn_affli_list.append(affli_list)\n",
        "\n",
        "print(cn_affli_list)\n",
        "len(cn_affli_list)"
      ],
      "metadata": {
        "id": "JkIEZ5-ATrUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a dictionary with the keys being the institute name, and the values being a list of its affiliations\n",
        "\n",
        "cn_dict = dict(zip(cn_list, cn_affli_list))\n",
        "print(cn_dict)"
      ],
      "metadata": {
        "id": "7nSvVBU_qKNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "new_path = open(\"China_institutes.csv\", \"w\")\n",
        "\n",
        "z = csv.writer(new_path)\n",
        "for new_k, new_v in cn_dict.items():\n",
        "    z.writerow([new_k, new_v])\n",
        "\n",
        "new_path.close()\n",
        "\n",
        "# open the csv file in excel and replace all the [\"  ['  ']  \"]  \",\"  ','  \",'  ',\"\n",
        "# with |, then split text into columns\n",
        "# there should be a better way of doing this, if someone knows please tell me "
      ],
      "metadata": {
        "id": "XyrEv7znqyED"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}